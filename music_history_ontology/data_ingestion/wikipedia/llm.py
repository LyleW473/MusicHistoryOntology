import os
import json

from typing import Dict, Any, Tuple, List
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from music_history_ontology.data_ingestion.wikipedia.constants import (
                                                                    QUERY_TEMPLATES,
                                                                    USER_EMBEDDING_TEMPLATES,
                                                                    CLASSES,
                                                                    )

def is_none_or_empty_str(value:Any) -> bool:
    """
    Checks if the given value is a "None" string or an empty string.

    Args:
        value (str): The value to check.

    Returns:
        bool: True if the value is None or an empty string, False otherwise.
    """
    if isinstance(value, str):
        if value == "none":
            return True
        return value.lower() == "none"
    # E.g., not a string, is not the string "none" or is not the empty string
    return False

class LLMTextGenerator:

    def __init__(self, role:str="information_extraction"):
        """
        Initialises the LLMTextGenerator with the specified role.

        Args:
            role (str): The role of the LLM. Supported roles are:
                        - "search_query_classification"
                        - "information_extraction"
                        - "alias_generation"
                        - "search_query_generation"
        """
        OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        if OPENAI_API_KEY is None:
            raise ValueError("OPENAI_API_KEY environment variable is not set.")
        if role not in QUERY_TEMPLATES:
            raise ValueError(f"Role '{role}' is not supported. Supported roles are: {list(QUERY_TEMPLATES.keys())}.")
        
        query_template = QUERY_TEMPLATES[role]
        query_template = ChatPromptTemplate([
                                            ("system", query_template),
                                            ("user", "{question}"),
                                            ])
        print("OPENAI_API_KEY", OPENAI_API_KEY)
        self.user_embedding_template = USER_EMBEDDING_TEMPLATES[role]

        self.role = role

        model = ChatOpenAI(api_key=OPENAI_API_KEY, model="gpt-4o-mini")
        self.chain = query_template | model
        
    def embed_text(self, **kwargs) -> str:

        """
        Embeds text using the LLM model.

        Args:
            text (str): The text to embed.
        """
        try:
            input_text = self.user_embedding_template.format(**kwargs)
        except KeyError as e:
            raise ValueError(f"Missing required keyword argument: {e}")
        return input_text
    
    def generate_answer(self, input_text:str) -> str:
        """
        Generates an answer using the LLM model.

        Args:
            input_text (str): The input text to generate an answer for.
        """
        generated_answer = self.chain.invoke({"question": input_text})
        generated_text = generated_answer.content
        return generated_text
    
    def extract_answer(self, generated_text:str) -> Tuple[Dict[str, str], None]:
        """
        Attempts to extract the JSON object from the generated text.
        
        Args:
            generated_text (str): The text generated by the LLM model to extract the JSON object from.
        """
        try:
            # print("Generated text:", generated_text)
            json_output = json.loads(generated_text)
            return json_output
        except Exception as e:
            print("Error parsing JSON object:", e)
            return None
        
    def postprocess_json(self, json_output:Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """
        Post-processes the ensure the JSON output is valid and contains the expected fields,
        dependent on the role of the LLM.

        Args:
            json_output (Dict[str, Any]): The JSON output to post-process.
            kwargs: Additional keyword arguments for specific roles.
        """
        if self.role == "search_query_classification":
            if json_output is not None:
                if "class" not in json_output:
                    json_output = None
                elif is_none_or_empty_str(json_output["class"]):
                    json_output = None
        
        elif self.role == "information_extraction":
            if json_output is not None:
                json_structure = kwargs.get("json_structure", None)
                assert json_structure is not None, "json_structure must be provided for information extraction."
                for field in json_structure.keys():
                    if field not in json_output:
                        json_output[field] = None
                    elif is_none_or_empty_str(json_output[field]):
                        json_output[field] = None
        
        elif self.role == "alias_generation":
            if json_output is not None:
                if "alias" not in json_output:
                    json_output = None
                elif is_none_or_empty_str(json_output["alias"]):
                    json_output = None
        
        elif self.role == "search_query_generation":
            if json_output is not None:
                if "search_query" not in json_output:
                    json_output = None
                elif is_none_or_empty_str(json_output["search_query"]):
                    json_output = None
        elif self.role == "time_interval_generation":
            if json_output is not None:
                if "time_intervals" not in json_output:
                    json_output = None
                else:
                    print(json_output)
                    if not isinstance(json_output["time_intervals"], dict):
                        json_output = None
                    
                    keys_to_remove = []
                    for generated_alias, data_dict in json_output["time_intervals"].items():
                        if not isinstance(data_dict, dict):
                            keys_to_remove.append(generated_alias)
                        if is_none_or_empty_str(generated_alias):
                            keys_to_remove.append(generated_alias)
                            continue
                        if "hasStartTime" not in data_dict:
                            keys_to_remove.append(generated_alias)
                            continue
                        if "hasEndTime" not in data_dict:
                            keys_to_remove.append(generated_alias)
                            continue
                        # Contains none of the most important fields
                        if (is_none_or_empty_str(data_dict["hasStartTime"]) and \
                            is_none_or_empty_str(data_dict["hasEndTime"]) and \
                            is_none_or_empty_str(data_dict["hasIntervalDate"])):

                            # Remove this entry from the JSON output
                            keys_to_remove.append(generated_alias)
                            continue
                        
                    # Remove the keys that are not valid
                    for key in keys_to_remove:
                        print(f"Removing invalid time interval: {key}")
                        print(json_output["time_intervals"][key])
                        del json_output["time_intervals"][key]
                    
        return json_output
    
    def execute(
            self,
            text:str=None,
            search_query:str=None, 
            json_structure:Dict[str, Any]=None, 
            class_hierarchy_tree:str=None,
            predicted_class:str=None,
            desired_class:str=None,
            property_mappings_for_class:Dict[str, Any]=None,
            all_generated_queries:List[str]=None,
            ) -> Tuple[Dict[str, str], None]:
        """
        Executes the text generation process.

        Args:
            text (str): The text to embed in the prompt. (All)
            search_query (str): The search query to classify. (Search query classification)
            json_structure (Dict[str, Any]): A structure describing the JSON fields to extract. (Information extraction)
            class_hierarchy_tree (str): The string equivalent of the class hierarchy tree JSON for the ontology. (Search query classification + Alias generation)
            predicted_class (str): The predicted class for the instance. (Alias generation)
            desired_class (str): The class that the generated search query should relate to (Search query generation)
            property_mappings_for_class (Dict[str, Any]): A mapping of properties and the datatype of those properties for a given class. (Search query generation)
            all_generated_queries (List[str]): A list of all previously generated search queries to avoid duplicate search queries. (Search query generation)
        """
        if self.role == "search_query_classification":
            input_text = self.embed_text(
                                        context_text=text, 
                                        search_query=search_query, 
                                        class_hierarchy_tree=class_hierarchy_tree
                                        )
        elif self.role == "information_extraction" or self.role == "time_interval_generation":
            json_fields = json.dumps(json_structure, indent=4) # Make pretty JSON
            bullet_points = "\n".join([f"- {field}" for field in json_structure.keys()])
            input_text = self.embed_text(
                                        text=text, 
                                        json_fields=json_fields,
                                        bullet_points=bullet_points
                                        )
            print(f"Input text: {input_text}")           
        elif self.role == "alias_generation":
            input_text = self.embed_text(
                                        context_text=text, 
                                        search_query=search_query, 
                                        class_hierarchy_tree=class_hierarchy_tree,
                                        predicted_class=predicted_class
                                        )
        elif self.role == "search_query_generation":
            input_text = self.embed_text(
                                        desired_class=desired_class, 
                                        class_hierarchy_tree=class_hierarchy_tree,
                                        property_mappings_for_class=property_mappings_for_class,
                                        all_generated_queries=all_generated_queries
                                        )
        generated_text = self.generate_answer(input_text)
        json_output = self.extract_answer(generated_text)
        json_output = self.postprocess_json(json_output, json_structure=json_structure)
        return json_output